{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-11T20:18:33.390165Z",
     "start_time": "2025-11-11T20:18:31.713150Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# --- System Integration ---\n",
    "# To allow this 'notebook' file to see the 'src' folder,\n",
    "# we need to tell Python that 'src' is one directory up.\n",
    "# This enables us to import our clean code from 'src' into the 'notebook'.\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "try:\n",
    "    # THIS IS OUR CLEAN CODE!\n",
    "    from src.processing.features import DamageDataPreprocessor\n",
    "    print(\"SUCCESS: 'src.processing.features.DamageDataPreprocessor' imported.\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: Could not import from 'src' folder.\")\n",
    "    print(\"Please verify that the file 'src/processing/features.py' exists.\")\n",
    "    # raise\n",
    "\n",
    "# --- 1. Data Loading ---\n",
    "file_path = \"../1900_2021_DISASTERS.xlsx - emdat data.csv\"\n",
    "df_raw = pd.read_csv(file_path)\n",
    "print(f\"Raw data loaded. Number of rows: {len(df_raw)}\")\n",
    "\n",
    "# --- 2. Data Preprocessing (Using Our 'System' Component) ---\n",
    "# Instantiating our clean class\n",
    "preprocessor = DamageDataPreprocessor(\n",
    "    features_to_use=['Disaster Subgroup', 'Continent', 'Disaster Group'],\n",
    "    target_col=\"Total Damages ('000 US$)\"\n",
    ")\n",
    "\n",
    "# By running 'fit_transform', we perform all those messy steps\n",
    "# (dropna, log, fillna) from the notebook in a single line.\n",
    "df_clean = preprocessor.fit_transform(df_raw)\n",
    "\n",
    "print(f\"Data processed. Available rows for the model: {len(df_clean)}\")\n",
    "\n",
    "# --- 3. Preparing Data for Model Training ---\n",
    "# 'df_clean' now only contains the columns needed for the model\n",
    "target = 'Log_Total_Damages'\n",
    "features = preprocessor.features_to_use # ['Disaster Subgroup', 'Continent', 'Disaster Group']\n",
    "\n",
    "X = df_clean[features]\n",
    "y = df_clean[target]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}, Test set size: {len(X_test)}\")\n",
    "\n",
    "# --- 4. Creating the Model Pipeline ---\n",
    "# This is a pipeline for the model itself.\n",
    "# Its purpose: Convert categorical features (text) into numbers (OneHotEncoder)\n",
    "# and then train the model (LinearRegression).\n",
    "\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore')), # 'handle_unknown' is important to prevent system crashes\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# --- 5. Training the Model ---\n",
    "print(\"Training the model pipeline...\")\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "print(\"Model trained.\")\n",
    "\n",
    "# --- 6. Evaluating the Model ---\n",
    "# Make predictions on the test set\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics (in the Logarithmic space)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Model Evaluation Results ---\")\n",
    "print(f\"R-squared (R2) Score: {r2:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(\"-----------------------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: 'src.processing.features.DamageDataPreprocessor' imported.\n",
      "Raw data loaded. Number of rows: 16126\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DamageDataPreprocessor.__init__() got an unexpected keyword argument 'features_to_use'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 33\u001B[39m\n\u001B[32m     29\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mRaw data loaded. Number of rows: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(df_raw)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     31\u001B[39m \u001B[38;5;66;03m# --- 2. Data Preprocessing (Using Our 'System' Component) ---\u001B[39;00m\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Instantiating our clean class\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m preprocessor = \u001B[43mDamageDataPreprocessor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     34\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfeatures_to_use\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mDisaster Subgroup\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mContinent\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mDisaster Group\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     35\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget_col\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mTotal Damages (\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m000 US$)\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m     36\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     38\u001B[39m \u001B[38;5;66;03m# By running 'fit_transform', we perform all those messy steps\u001B[39;00m\n\u001B[32m     39\u001B[39m \u001B[38;5;66;03m# (dropna, log, fillna) from the notebook in a single line.\u001B[39;00m\n\u001B[32m     40\u001B[39m df_clean = preprocessor.fit_transform(df_raw)\n",
      "\u001B[31mTypeError\u001B[39m: DamageDataPreprocessor.__init__() got an unexpected keyword argument 'features_to_use'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T20:20:00.125618Z",
     "start_time": "2025-11-11T20:19:59.927006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# --- System Integration (Same) ---\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "try:\n",
    "    from src.processing.features import DamageDataPreprocessor\n",
    "    print(\"SUCCESS: 'src.processing.features.DamageDataPreprocessor' imported.\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: Could not import from 'src' folder.\")\n",
    "    raise\n",
    "\n",
    "# --- 1. Data Loading (Same) ---\n",
    "file_path = \"../1900_2021_DISASTERS.xlsx - emdat data.csv\"\n",
    "df_raw = pd.read_csv(file_path)\n",
    "\n",
    "# --- 2. Data Preprocessing (Our Class Changed) ---\n",
    "\n",
    "# UPDATE: Our class no longer takes 'features_to_use'.\n",
    "# It only takes 'target_col'.\n",
    "preprocessor = DamageDataPreprocessor(\n",
    "    target_col=\"Total Damages ('000 US$)\"\n",
    ")\n",
    "\n",
    "# df_clean NOW CONTAINS ALL COLUMNS\n",
    "# (but only for the 5000+ rows where the target is valid)\n",
    "df_clean = preprocessor.fit_transform(df_raw)\n",
    "\n",
    "print(f\"Data processed. Available rows for the model: {len(df_clean)}\")\n",
    "\n",
    "# --- 3. Preparing Data for Model Training (Critical Change) ---\n",
    "target = 'Log_Total_Damages'\n",
    "\n",
    "# We must manually define our features\n",
    "categorical_features = ['Disaster Subgroup', 'Continent', 'Disaster Group']\n",
    "numerical_features = ['Total Deaths', 'No Injured', 'No Affected', 'Dis Mag Value', 'Start Year']\n",
    "\n",
    "# UPDATE: We must CAREFULLY select X and y from 'df_clean'\n",
    "# X should contain only the features we will use\n",
    "X = df_clean[categorical_features + numerical_features]\n",
    "# y should contain only the new logarithmic target\n",
    "y = df_clean[target]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}, Test set size: {len(X_test)}\")\n",
    "\n",
    "# --- 4. Advanced Model Pipeline (ColumnTransformer) ---\n",
    "# THERE IS NO CHANGE IN THIS PART.\n",
    "# BECAUSE WE FIXED THE FLAWED COMPONENT (features.py).\n",
    "# NOW 'SimpleImputer(strategy='median')' WILL ONLY RECEIVE NUMERICAL DATA.\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "model_pipeline_v2 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_pipeline),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# --- 5. Training the Model ---\n",
    "print(\"Training model pipeline v2 (Refactored)...\")\n",
    "model_pipeline_v2.fit(X_train, y_train) # <-- The place where the error occurred, should work CORRECTLY now\n",
    "print(\"Model v2 trained.\")\n",
    "\n",
    "# --- 6. Evaluating the Model ---\n",
    "y_pred = model_pipeline_v2.predict(X_test)\n",
    "\n",
    "r2_v2 = r2_score(y_test, y_pred)\n",
    "mse_v2 = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Model v2 Evaluation Results (Numerical Features Added) ---\")\n",
    "print(f\"R-squared (R2) Score: {r2_v2:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_v2:.4f}\")\n",
    "print(\"-----------------------------------\")"
   ],
   "id": "a6e05b6e69b010a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: 'src.processing.features.DamageDataPreprocessor' imported.\n",
      "Data processed. Available rows for the model: 5245\n",
      "Training set size: 4196, Test set size: 1049\n",
      "Training model pipeline v2 (Refactored)...\n",
      "Model v2 trained.\n",
      "\n",
      "--- Model v2 Evaluation Results (Numerical Features Added) ---\n",
      "R-squared (R2) Score: 0.0915\n",
      "Mean Squared Error (MSE): 1.1282\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "38b82f9b488e356b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
